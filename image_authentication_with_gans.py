# -*- coding: utf-8 -*-
"""Image Authentication with GANs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R-32tBAVpdKzdNIXMcy553jAUTG-4IkJ
"""

#########load libraries
import numpy as np
import pandas as pd
import keras
from keras.layers import (Conv2D, Conv2DTranspose, Dropout, Input, Flatten, LeakyReLU,Dense,Reshape )
from keras.models import Model, Sequential
from keras.datasets import mnist

# load the images into memory
#from keras.utils.vis_utils import plot_model
#from numpy import vstack, ones
#from numpy.random.mtrand import rand, randint, randn
(trainX, trainy), (testX, testy) = mnist.load_data()
# summarize the shape of the dataset
print('Train', trainX.shape, trainy.shape)
print('Test', testX.shape, testy.shape)

from keras.backend import binary_crossentropy
####### define discriminator model
def define_discriminator(in_shape=(28, 28, 1)):
  model = Sequential()
  model.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=in_shape))
  model.add(LeakyReLU(alpha=0.2))
  model.add(Dropout(0.4))
  model.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same'))
  model.add(LeakyReLU(alpha=0.2))
  model.add(Dropout(0.4))
  model.add(Flatten())
  #model.add(Dense(256, activation='sigmoid'))
  model.add(Dense(1, activation='sigmoid'))
  # compile model
  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
  return model

d_model=define_discriminator()

##### normalize or scale the data
def load_real_samples():
  # expand to 3d, e.g. add channels dimension
  X = np.expand_dims(trainX, axis=-1)
  # convert from unsigned ints to floats
  X = X.astype('float32')
  # scale from [0,255] to [0,1]
  X = X / 255.0
  return X

def generate_real_samples(dataset, n_samples):
  # choose random instances
  ix = np.random.randint(0, dataset.shape[0], n_samples)
  # retrieve selected images
  X = dataset[ix]
  # generate 'real' class labels (1)
  y = np.ones((n_samples, 1))
  return X, y

def generate_fake_samples(n_samples):
  # generate uniform random numbers in [0,1]
  X = np.random.rand(28 * 28 * n_samples)
  # reshape into a batch of grayscale images
  X = X.reshape((n_samples, 28, 28, 1))
  # generate 'fake' class labels (0)
  y = np.zeros((n_samples, 1))
  return X, y

# train the discriminator model
def train_discriminator(model, dataset, n_iter=100, n_batch=256):
   half_batch = int(n_batch / 2)
   # manually enumerate epochs
   for i in range(n_iter):
      # get randomly selected 'real' samples
      X_real, y_real = generate_real_samples(dataset, half_batch)
      # update discriminator on real samples
      _, real_acc = model.train_on_batch(X_real, y_real)
     # generate 'fake' examples
      X_fake, y_fake = generate_fake_samples(half_batch)
     # update discriminator on fake samples
      _, fake_acc = model.train_on_batch(X_fake, y_fake)
     # summarize performance
      print(i+1,"real>> ",real_acc*100,"fake>>",fake_acc*100)
     #print('>%d real=%.0f%% fake=%.0f%%' % (i + 1, real_acc * 100, fake_acc * 100))

# define the discriminator model
model = define_discriminator()
# summarize the model
model.summary()
# plot the model
#plot_model(model, to_file='discriminator_plot.png', show_shapes=True, show_layer_names=Tr
# load image data
dataset = load_real_samples()
# fit the model
train_discriminator(model, dataset)

# define the generator model
def define_generator(latent_dim):
  model = Sequential()
  n_nodes = 128 * 7 * 7
  model.add(Dense(n_nodes, input_dim=latent_dim))
  model.add(LeakyReLU(alpha=0.2))
  model.add(Reshape((7, 7, 128)))
  # upsample to 14x14
  model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))
  model.add(LeakyReLU(alpha=0.2))
  # upsample to 28x28
  model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))
  model.add(LeakyReLU(alpha=0.2))
  model.add(Conv2D(1, (7, 7), activation='sigmoid', padding='same'))
  return model

g_model=define_generator(100)

!pip install tensorflow

from keras.models import Sequential
import matplotlib.pyplot as plt
import tensorflow as tf  # Import TensorFlow

# define the size of the latent space
latent_dim = 100
# define the generator model
model = define_generator(latent_dim)
# summarise the model
model.summary()

# Plot the model architecture as a graph
# Note: You may need to adjust the figsize and dpi based on your preferences
plot_model_path = 'model_plot.png'  # Specify the path to save the plot
tf.keras.utils.plot_model(model, to_file=plot_model_path, show_shapes=True, show_layer_names=True)

# Display the plot
img = plt.imread(plot_model_path)
plt.figure(figsize=(10, 10))
plt.imshow(img)
plt.axis('off')
plt.show()

def define_gan(generator, discriminator):
    # Make the discriminator non-trainable during GAN training
    discriminator.trainable = False
    # Connect the generator to the discriminator
    model = Sequential()
    model.add(generator)
    model.add(discriminator)
    # Compile the GAN model
    model.compile(loss='binary_crossentropy', optimizer='adam')
    return model

def train_gan(generator, discriminator, gan, dataset, latent_dim, n_epochs=100, n_batch=256):
    for epoch in range(n_epochs):
        for _ in range(len(dataset) // n_batch):
            # Train the discriminator
            X_real, y_real = generate_real_samples(dataset, n_batch)
            d_loss_real = discriminator.train_on_batch(X_real, y_real)

            X_fake, y_fake = generate_fake_samples(generator, latent_dim, n_batch)
            d_loss_fake = discriminator.train_on_batch(X_fake, y_fake)

            # Train the GAN (only generator part)
            X_gan = generate_latent_points(latent_dim, n_batch)
            y_gan = np.ones((n_batch, 1))
            g_loss = gan.train_on_batch(X_gan, y_gan)

            # Summarize progress
            print(f"Epoch {epoch + 1}/{n_epochs}, D Loss Real: {d_loss_real[0]}, D Loss Fake: {d_loss_fake[0]}, G Loss: {g_loss}")

        # Optionally, save generated images at each epoch
        if (epoch + 1) % save_interval == 0:
            save_generated_images(generator, epoch)

def define_gan(generator, discriminator):
    # Make the discriminator non-trainable during GAN training
    discriminator.trainable = False
    # Connect the generator to the discriminator
    model = Sequential()
    model.add(generator)
    model.add(discriminator)
    # Compile the GAN model
    model.compile(loss='binary_crossentropy', optimizer='adam')
    return model

def train_gan(generator, discriminator, gan, dataset, latent_dim, n_epochs=100, n_batch=256):
    for epoch in range(n_epochs):
        for _ in range(len(dataset) // n_batch):
            # Train the discriminator
            X_real, y_real = generate_real_samples(dataset, n_batch)
            d_loss_real = discriminator.train_on_batch(X_real, y_real)

            X_fake, y_fake = generate_fake_samples(generator, latent_dim, n_batch)
            d_loss_fake = discriminator.train_on_batch(X_fake, y_fake)

            # Train the GAN (only generator part)
            X_gan = generate_latent_points(latent_dim, n_batch)
            y_gan = np.ones((n_batch, 1))
            g_loss = gan.train_on_batch(X_gan, y_gan)

            # Summarize progress
            print(f"Epoch {epoch + 1}/{n_epochs}, D Loss Real: {d_loss_real[0]}, D Loss Fake: {d_loss_fake[0]}, G Loss: {g_loss}")

        # Optionally, save generated images at each epoch
        if (epoch + 1) % save_interval == 0:
            save_generated_images(generator, epoch)

def generate_latent_points(latent_dim, n_samples):
    # Generate n_samples random points in the latent space
    x_input = np.random.randn(latent_dim * n_samples)
    # Reshape into a batch of inputs for the network
    x_input = x_input.reshape(n_samples, latent_dim)
    return x_input